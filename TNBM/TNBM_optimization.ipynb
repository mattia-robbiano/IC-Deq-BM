{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import quimb\n",
    "import quimb.tensor as qtn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimension of dataset: 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 9\n",
    "D = 8\n",
    "sigma = 0.09\n",
    "\n",
    "# create a random MPS as our initial target to optimize\n",
    "psi = qtn.MPS_rand_state(L, bond_dim=D)\n",
    "Ommd = Ommd(L, sigma)\n",
    "dataset = get_bars_and_stripes(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPS_dataset = []\n",
    "for data in dataset:\n",
    "    MPS_dataset.append(qtn.MPS_computational_state(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(psi,dataset,Ommd):\n",
    "    loss = 0\n",
    "    for data in dataset:\n",
    "        #y = qtn.MPS_computational_state(data)\n",
    "        loss += MMD(psi, data, Ommd, sigma, L, D)\n",
    "    loss = loss / len(dataset)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TNOptimizer(d=928, backend=jax)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnopt = qtn.TNOptimizer(\n",
    "    # the tensor network we want to optimize\n",
    "    psi,\n",
    "    # the functions specfying the loss and normalization\n",
    "    loss_fn=loss_fn,\n",
    "    #norm_fn=norm_fn,\n",
    "    # we specify constants so that the arguments can be converted\n",
    "    # to the  desired autodiff backend automatically\n",
    "    loss_constants={\"dataset\": MPS_dataset, \"Ommd\": Ommd},\n",
    "    # the underlying algorithm to use for the optimization\n",
    "    # 'l-bfgs-b' is the default and often good for fast initial progress\n",
    "    optimizer=\"adam\",\n",
    "    # which gradient computation backend to use\n",
    "    autodiff_backend=\"jax\",\n",
    ")\n",
    "tnopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-02-27 11:26:15.691962: E external/xla/xla/service/slow_operation_alarm.cc:73] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %multiply.671 = f64[503,503,2,2]{2,3,1,0} multiply(f64[503,503,2,2]{2,3,1,0} %constant.692, f64[503,503,2,2]{2,3,1,0} %broadcast.341)\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2025-02-27 11:26:16.359547: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.667825091s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %multiply.671 = f64[503,503,2,2]{2,3,1,0} multiply(f64[503,503,2,2]{2,3,1,0} %constant.692, f64[503,503,2,2]{2,3,1,0} %broadcast.341)\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "+1.940453589090 [best: +1.940453589090] : : 2it [01:07, 33.59s/it]                     \n"
     ]
    }
   ],
   "source": [
    "psi_opt = tnopt.optimize(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
